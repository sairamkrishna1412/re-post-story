{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker news data set\n",
    "* hacker news is a popular site where technology related stories and posts are voted and commented upon similar to reddit.hacker newa is extermely popular in technology and start up circles, and the posts that make it to the top of hacker listings can get hundreds of thousands of visitors as a result.\n",
    "* In this project we will work with a data set of subbmissions to popular techology site [hacker news.](https://news.ycombinator.com/)\n",
    "* You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "* We're specifically interested in posts whose titles begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question. users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# introduction:\n",
    "* first we will open the hacker_news.csv file and make it a list of lists and remove the header row from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file=open(\"hacker_news-copy1.csv\")\n",
    "read_file=reader(opened_file)\n",
    "hn=list(read_file)\n",
    "print(hn[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']]\n"
     ]
    }
   ],
   "source": [
    "header=hn[0]\n",
    "hn=hn[1:]\n",
    "print(hn[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seperating the data set into 3 parts:\n",
    "* the data set which we are given is divided into three parts :\n",
    "1. ask: it stores all the post titles beginning with ASK HN.\n",
    "2. show: it stores all the post titles beginning with SHOW HN.\n",
    "3. other: it stores other files which dont have either ASK HN or SHOW HN in their titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements in ask:  1744\n",
      "number of elements in show:   1162\n",
      "number of elements in other:  17194\n"
     ]
    }
   ],
   "source": [
    "ask=[]\n",
    "show=[]\n",
    "other=[]\n",
    "for i in hn:\n",
    "    title=i[1]\n",
    "    title_l=title.lower()\n",
    "    if title_l.startswith(\"ask hn\")==True:\n",
    "        ask.append(i)\n",
    "    elif title_l.startswith(\"show hn\")==True:\n",
    "        show.append(i)\n",
    "    else:\n",
    "        other.append(i)\n",
    "print(\"number of elements in ask: \",len(ask))\n",
    "print(\"number of elements in show:  \",len(show))\n",
    "print(\"number of elements in other: \",len(other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will now print the first five rows of ask list and you can observe that all the titles in this list start with ASK HN.\n",
    "* we will also going to print the first five rows of show list and all the titles start with SHOW HN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']\n",
      "['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n",
      "\n",
      "\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n"
     ]
    }
   ],
   "source": [
    "for i in ask[:5]:\n",
    "    print(i)\n",
    "print('')\n",
    "print('')\n",
    "for j in show[:5]:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the average number of points in ask and show lists .\n",
    "* to find the average number of points in ask and show lists we need to first initiate ask_c and show_c to 0\n",
    "* loop through the ask list, number of points is in the fifth coloumn in ask list we need to get the element at index 3 in each row. dont forget to convert the value to integer type to perform addition to it.\n",
    "* calculate points and assign it to variable ask_c .\n",
    "* similarly do the same operations on show list and find the show_c\n",
    "* after that calculate average points for both the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of points for ask posts:   26268\n",
      "total number of points for show posts:  32019\n",
      "average ask points:  15.061926605504587\n",
      "average show points:  27.555077452667813\n"
     ]
    }
   ],
   "source": [
    "ask_p=0\n",
    "show_p=0\n",
    "for i in ask:\n",
    "    points_a=int(i[3])\n",
    "    ask_p+=points_a\n",
    "print(\"total number of points for ask posts:  \",ask_p)\n",
    "for j in show:\n",
    "    points_s=int(j[3])\n",
    "    show_p+=points_s\n",
    "print(\"total number of points for show posts: \",show_p)\n",
    "print(\"average ask points: \",ask_p/len(ask))\n",
    "print(\"average show points: \",show_p/len(show))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* now we will create 2 dictionaries which will store counts and points per hour\n",
    "* first import datetime module as dt because we will need it to convert the created_at coloumn at index 6 in hour.\n",
    "* then create an empty list named result list.which we will be a list of lists\n",
    "* append the date and points to the list. here date and points form for each row form a list and stored into the bigger list res_show\n",
    "* create 2 dictionaries count_by_hour and points_by_hour which will be a frequency table where the key is hour and the value is number of posts , number of points for that hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "res_show=[]\n",
    "for i in show:\n",
    "    res_show.append([i[6],int(i[3])])\n",
    "for i in res_show:\n",
    "    time=i[0]\n",
    "    dformat=(\"%m/%d/%Y %H:%M\")\n",
    "    hour=dt.datetime.strptime(time,dformat).strftime(\"%H\")\n",
    "    i[0]=hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': 86, '22': 46, '18': 61, '07': 26, '20': 60, '05': 19, '16': 93, '19': 55, '15': 78, '03': 27, '17': 93, '06': 16, '02': 30, '13': 99, '08': 34, '21': 47, '04': 26, '11': 44, '12': 61, '23': 36, '09': 30, '01': 28, '10': 36, '00': 31}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'14': 2187, '22': 1856, '18': 2215, '07': 494, '20': 1819, '05': 104, '16': 2634, '19': 1702, '15': 2228, '03': 679, '17': 2521, '06': 375, '02': 340, '13': 2438, '08': 519, '21': 866, '04': 386, '11': 1480, '12': 2543, '23': 1526, '09': 553, '01': 700, '10': 681, '00': 1173}\n"
     ]
    }
   ],
   "source": [
    "count_by_hour={}\n",
    "points_by_hour={}\n",
    "for i in res_show:\n",
    "    hour=i[0]\n",
    "    points=i[1]\n",
    "    if hour in count_by_hour:\n",
    "        count_by_hour[hour]+=1\n",
    "        points_by_hour[hour]+=points\n",
    "    else:\n",
    "        count_by_hour[hour]=1\n",
    "        points_by_hour[hour]=points\n",
    "print(count_by_hour)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(points_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': 25.430232558139537, '22': 40.34782608695652, '18': 36.31147540983606, '07': 19.0, '20': 30.316666666666666, '05': 5.473684210526316, '16': 28.322580645161292, '19': 30.945454545454545, '15': 28.564102564102566, '03': 25.14814814814815, '17': 27.107526881720432, '06': 23.4375, '02': 11.333333333333334, '13': 24.626262626262626, '08': 15.264705882352942, '21': 18.425531914893618, '04': 14.846153846153847, '11': 33.63636363636363, '12': 41.68852459016394, '23': 42.388888888888886, '09': 18.433333333333334, '01': 25.0, '10': 18.916666666666668, '00': 37.83870967741935}\n"
     ]
    }
   ],
   "source": [
    "average_points_by_hour={}\n",
    "for i in points_by_hour:\n",
    "    average_points_by_hour[i]=points_by_hour[i]/count_by_hour[i]\n",
    "print(average_points_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will now create a list which store lists within it and each sublist is of 2 elements where the first element is hour and the second element is average points for that hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.430232558139537, 14], [40.34782608695652, 22], [36.31147540983606, 18], [19.0, 7], [30.316666666666666, 20], [5.473684210526316, 5], [28.322580645161292, 16], [30.945454545454545, 19], [28.564102564102566, 15], [25.14814814814815, 3], [27.107526881720432, 17], [23.4375, 6], [11.333333333333334, 2], [24.626262626262626, 13], [15.264705882352942, 8], [18.425531914893618, 21], [14.846153846153847, 4], [33.63636363636363, 11], [41.68852459016394, 12], [42.388888888888886, 23], [18.433333333333334, 9], [25.0, 1], [18.916666666666668, 10], [37.83870967741935, 0]]\n"
     ]
    }
   ],
   "source": [
    "avg_points=[]\n",
    "for i in average_points_by_hour:\n",
    "    avg_points.append([average_points_by_hour[i],int(i)])\n",
    "print(avg_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting and printing values from a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[[42.388888888888886, 23], [41.68852459016394, 12], [40.34782608695652, 22], [37.83870967741935, 0], [36.31147540983606, 18], [33.63636363636363, 11], [30.945454545454545, 19], [30.316666666666666, 20], [28.564102564102566, 15], [28.322580645161292, 16], [27.107526881720432, 17], [25.430232558139537, 14], [25.14814814814815, 3], [25.0, 1], [24.626262626262626, 13], [23.4375, 6], [19.0, 7], [18.916666666666668, 10], [18.433333333333334, 9], [18.425531914893618, 21], [15.264705882352942, 8], [14.846153846153847, 4], [11.333333333333334, 2], [5.473684210526316, 5]]\n"
     ]
    }
   ],
   "source": [
    "sorted_avg_points=sorted(avg_points,reverse=True)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(sorted_avg_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:00 : 42.39 average points per post\n",
      "12:00 : 41.69 average points per post\n",
      "22:00 : 40.35 average points per post\n",
      "0:00 : 37.84 average points per post\n",
      "18:00 : 36.31 average points per post\n",
      "11:00 : 33.64 average points per post\n",
      "19:00 : 30.95 average points per post\n",
      "20:00 : 30.32 average points per post\n",
      "15:00 : 28.56 average points per post\n",
      "16:00 : 28.32 average points per post\n",
      "17:00 : 27.11 average points per post\n",
      "14:00 : 25.43 average points per post\n",
      "3:00 : 25.15 average points per post\n",
      "1:00 : 25.00 average points per post\n",
      "13:00 : 24.63 average points per post\n",
      "6:00 : 23.44 average points per post\n",
      "7:00 : 19.00 average points per post\n",
      "10:00 : 18.92 average points per post\n",
      "9:00 : 18.43 average points per post\n",
      "21:00 : 18.43 average points per post\n",
      "8:00 : 15.26 average points per post\n",
      "4:00 : 14.85 average points per post\n",
      "2:00 : 11.33 average points per post\n",
      "5:00 : 5.47 average points per post\n"
     ]
    }
   ],
   "source": [
    "for i in sorted_avg_points:\n",
    "    print(\"{}:00 : {:.2f} average points per post\".format(i[1],i[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion:\n",
    "* clearly we can see that 23:00 hour of the day tht is 11:00 pm has the maximum of 42.39 average points per post.\n",
    "* so you will probably receive more points if you post SHOW HN type at 11:00 pm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
